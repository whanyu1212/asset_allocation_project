{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>U.S. 30 Day TBill TR</th>\n",
       "      <th>Russell 2000 TR</th>\n",
       "      <th>S&amp;P 500 TR</th>\n",
       "      <th>LB LT Gvt/Credit TR</th>\n",
       "      <th>MSCI EAFE TR</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-31</td>\n",
       "      <td>0.80</td>\n",
       "      <td>8.420000</td>\n",
       "      <td>6.10</td>\n",
       "      <td>-6.14</td>\n",
       "      <td>4.84</td>\n",
       "      <td>1980s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-02-29</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-7.92</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1980s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-03-31</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-18.109999</td>\n",
       "      <td>-9.87</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-10.62</td>\n",
       "      <td>1980s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-04-30</td>\n",
       "      <td>1.26</td>\n",
       "      <td>6.270001</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.17</td>\n",
       "      <td>9.46</td>\n",
       "      <td>1980s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-05-31</td>\n",
       "      <td>0.81</td>\n",
       "      <td>8.340000</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.81</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1980s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  U.S. 30 Day TBill TR   Russell 2000 TR   S&P 500 TR   \\\n",
       "0  1980-01-31                   0.80          8.420000         6.10   \n",
       "1  1980-02-29                   0.89         -1.800000         0.31   \n",
       "2  1980-03-31                   1.21        -18.109999        -9.87   \n",
       "3  1980-04-30                   1.26          6.270001         4.29   \n",
       "4  1980-05-31                   0.81          8.340000         5.62   \n",
       "\n",
       "   LB LT Gvt/Credit TR   MSCI EAFE TR  Period  \n",
       "0                 -6.14           4.84  1980s  \n",
       "1                 -7.92          -0.40  1980s  \n",
       "2                 -0.43         -10.62  1980s  \n",
       "3                 14.17           9.46  1980s  \n",
       "4                  5.81           4.67  1980s  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/processed_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.63497336, 12.02246045,  9.81895654, 11.90354087])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.drop([\"Date\",\"Period\",\"U.S. 30 Day TBill TR \"], axis=1).mean()*12).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.08941865, 53.39633295, 42.06009394, 62.73631231])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.drop([\"Date\",\"Period\",\"U.S. 30 Day TBill TR \"], axis=1).std()*12).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32.19561759, 21.75402575,  2.56856258, 17.68042371],\n",
       "       [21.75402575, 19.79978037,  3.20515945, 14.97543642],\n",
       "       [ 2.56856258,  3.20515945, 12.28507988,  1.97896793],\n",
       "       [17.68042371, 14.97543642,  1.97896793, 27.33225613]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"Date\",\"Period\", \"U.S. 30 Day TBill TR \"], axis=1).cov().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0529466779"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"U.S. 30 Day TBill TR \"].mean()*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28742221564609893"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"U.S. 30 Day TBill TR \"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33686311186"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8 * df[\"U.S. 30 Day TBill TR \"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2861619990880717"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8 * df[\"U.S. 30 Day TBill TR \"].mean() + np.dot(np.array([0,0.1922,0.45,0.35]),df.drop([\"Date\",\"Period\",\"U.S. 30 Day TBill TR \"], axis=1).mean().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop([\"Date\",\"Period\",\"U.S. 30 Day TBill TR \"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(df1.corr(), # You can use df.corr() to compute the correlation matrix\n",
    "                x=df1.columns,\n",
    "                y=df1.columns,\n",
    "                zmin=-1, # Set the color scale range from -1 to 1 for correlation values\n",
    "                zmax=1,\n",
    "                color_continuous_scale='RdBu_r',\n",
    "                text_auto=True,# Choose a color scale    e the correlation matrix as text annotations\n",
    "                labels=dict(color='Correlation'))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Heatmap with Text Annotations\",\n",
    "    xaxis_title=\"X\",\n",
    "    yaxis_title=\"Y\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.melt(\n",
    "        df.query(\"Period=='1980s'\").drop(\"Period\", axis=1),\n",
    "        id_vars=[\"Date\"],\n",
    "        var_name=\"Indexes\",\n",
    "        value_name=\"Value\",\n",
    "    )\n",
    "    .sort_values(by=[\"Date\", \"Indexes\"])\n",
    "    .groupby(\"Indexes\")\n",
    "    .agg(\n",
    "        Monthly_average_return=(\"Value\", \"mean\"),\n",
    "        Monthly_standard_deviation=(\"Value\", \"std\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .assign(Annualized_return=lambda x: x[\"Monthly_average_return\"] * 12)\n",
    "    .assign(Annualized_standard_deviation=lambda x: x[\"Monthly_standard_deviation\"] * 12 ** 0.5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russell 2000 TR</th>\n",
       "      <th>S&amp;P 500 TR</th>\n",
       "      <th>LB LT Gvt/Credit TR</th>\n",
       "      <th>MSCI EAFE TR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-0.011054</td>\n",
       "      <td>-0.015574</td>\n",
       "      <td>-0.022782</td>\n",
       "      <td>-0.057837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-0.028441</td>\n",
       "      <td>-0.020766</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.012011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.079044</td>\n",
       "      <td>0.036739</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>0.055824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.008313</td>\n",
       "      <td>-0.061418</td>\n",
       "      <td>-0.050435</td>\n",
       "      <td>0.015237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>-0.045431</td>\n",
       "      <td>-0.009081</td>\n",
       "      <td>0.036252</td>\n",
       "      <td>0.005331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-0.088102</td>\n",
       "      <td>-0.056791</td>\n",
       "      <td>0.045989</td>\n",
       "      <td>-0.087549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>-0.113716</td>\n",
       "      <td>-0.071762</td>\n",
       "      <td>0.100108</td>\n",
       "      <td>-0.108083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.150428</td>\n",
       "      <td>0.107723</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>0.096275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>-0.004912</td>\n",
       "      <td>-0.005059</td>\n",
       "      <td>-0.037082</td>\n",
       "      <td>-0.021764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>-0.021750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Russell 2000 TR   S&P 500 TR   LB LT Gvt/Credit TR   MSCI EAFE TR \n",
       "240         -0.011054    -0.015574             -0.022782      -0.057837\n",
       "241         -0.028441    -0.020766              0.010098       0.012011\n",
       "242          0.079044     0.036739              0.006827       0.055824\n",
       "243          0.008313    -0.061418             -0.050435       0.015237\n",
       "244         -0.045431    -0.009081              0.036252       0.005331\n",
       "..                ...          ...                   ...            ...\n",
       "355         -0.088102    -0.056791              0.045989      -0.087549\n",
       "356         -0.113716    -0.071762              0.100108      -0.108083\n",
       "357          0.150428     0.107723              0.138029       0.096275\n",
       "358         -0.004912    -0.005059             -0.037082      -0.021764\n",
       "359          0.004746     0.008533              0.021636      -0.021750\n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df.query(\"Period=='2000s'\").drop([\"Date\",\"Period\",\"U.S. 30 Day TBill TR \"],axis=1)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = test_df.mean()\n",
    "mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = test_df.cov()\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "from pypfopt.expected_returns import ema_historical_return\n",
    "from pypfopt.risk_models import exp_cov\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt.plotting import plot_efficient_frontier\n",
    "from pypfopt.plotting import plot_weights\n",
    "from pypfopt.cla import CLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = expected_returns.ema_historical_return(test_df, returns_data = True,compounding=False, span=12)\n",
    "Sigma = risk_models.exp_cov(test_df, returns_data = True, span=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef = EfficientFrontier(mu, Sigma)\n",
    "ef.min_volatility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef = EfficientFrontier(mu, Sigma)\n",
    "ef.max_sharpe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_ef = np.arange(0, 1, 0.001)\n",
    "vol_ef = []\n",
    "for i in np.arange(0, 1, 0.001):\n",
    "    ef = EfficientFrontier(mu, Sigma)\n",
    "    ef.efficient_return(i)\n",
    "    vol_ef.append(ef.portfolio_performance()[1])\n",
    "\n",
    "ef = EfficientFrontier(mu, Sigma)\n",
    "ef.min_volatility()\n",
    "min_vol_ret = ef.portfolio_performance()[0]\n",
    "min_vol_vol = ef.portfolio_performance()[1]\n",
    "\n",
    "ef = EfficientFrontier(mu, Sigma)\n",
    "ef.max_sharpe()\n",
    "max_sharpe_ret = ef.portfolio_performance()[0]\n",
    "max_sharpe_vol = ef.portfolio_performance()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_vol_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_vol_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef = EfficientFrontier(mu, Sigma)\n",
    "ef.min_volatility()\n",
    "ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = [15,10])\n",
    "\n",
    "sns.lineplot(x = vol_ef, y = ret_ef, label = \"Efficient Frontier\", ax = ax, color = \"b\")\n",
    "# sns.scatterplot(x = [min_vol_vol], y = [min_vol_ret], ax = ax, label = \"Minimum Variance Portfolio\", color = \"purple\", s = 100)\n",
    "# sns.scatterplot(x = [max_sharpe_vol], y = [max_sharpe_ret], ax = ax, label = \"Maximum Sharpe Portfolio\", color = \"green\", s = 100)\n",
    "# sns.lineplot(x = [0, max_sharpe_vol, 1], y = [0.009, max_sharpe_ret, 3.096], label = \"Capital Market Line\", ax = ax, color = \"r\")\n",
    "\n",
    "# ax.set(xlim = [0, 0.4])\n",
    "# ax.set(ylim = [0, 1])\n",
    "ax.set_xlabel(\"Volatility\")\n",
    "ax.set_ylabel(\"Mean Return\")\n",
    "plt.legend(fontsize='large')\n",
    "plt.title(\"Efficient Frontier\", fontsize = '20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = test_df.mean()*12\n",
    "Sigma = test_df.cov()*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- How many assests to include in each portfolio\n",
    "n_assets = 4\n",
    "#-- How many portfolios to generate\n",
    "n_portfolios = 1000\n",
    "\n",
    "#-- Initialize empty list to store mean-variance pairs for plotting\n",
    "mean_variance_pairs = []\n",
    "\n",
    "np.random.seed(75)\n",
    "#-- Loop through and generate lots of random portfolios\n",
    "for i in range(n_portfolios):\n",
    "    #- Choose assets randomly without replacement\n",
    "    assets = np.random.choice(list(test_df.columns), n_assets, replace=False)\n",
    "    #- Choose weights randomly\n",
    "    weights = np.random.rand(n_assets)\n",
    "    #- Ensure weights sum to 1\n",
    "    weights = weights/sum(weights)\n",
    "\n",
    "    #-- Loop over asset pairs and compute portfolio return and variance\n",
    "    #- https://quant.stackexchange.com/questions/43442/portfolio-variance-explanation-for-equation-investments-by-zvi-bodie\n",
    "    portfolio_E_Variance = 0\n",
    "    portfolio_E_Return = 0\n",
    "    for i in range(len(assets)):\n",
    "        portfolio_E_Return += weights[i] * mus.loc[assets[i]]\n",
    "        for j in range(len(assets)):\n",
    "            #-- Add variance/covariance for each asset pair\n",
    "            #- Note that when i==j this adds the variance\n",
    "            portfolio_E_Variance += weights[i] * weights[j] * cov.loc[assets[i], assets[j]]\n",
    "            \n",
    "    #-- Add the mean/variance pairs to a list for plotting\n",
    "    mean_variance_pairs.append([portfolio_E_Return, portfolio_E_Variance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plot the risk vs. return of randomly generated portfolios\n",
    "#-- Convert the list from before into an array for easy plotting\n",
    "mean_variance_pairs = np.array(mean_variance_pairs)\n",
    "\n",
    "risk_free_rate=0 #-- Include risk free rate here\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=mean_variance_pairs[:,1]**0.5, y=mean_variance_pairs[:,0], \n",
    "                      marker=dict(color=(mean_variance_pairs[:,0]-risk_free_rate)/(mean_variance_pairs[:,1]**0.5), \n",
    "                                  showscale=True, \n",
    "                                  size=7,\n",
    "                                  line=dict(width=1),\n",
    "                                  colorscale=\"RdBu\",\n",
    "                                  colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "                                 ), \n",
    "                      mode='markers'))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  xaxis=dict(title='Annualised Risk (Volatility)'),\n",
    "                  yaxis=dict(title='Annualised Return'),\n",
    "                  title='Sample of Random Portfolios',\n",
    "                  width=850,\n",
    "                  height=500)\n",
    "# fig.update_xaxes(range=[0.18, 0.32])\n",
    "# fig.update_yaxes(range=[0.02,0.27])\n",
    "fig.update_layout(coloraxis_colorbar=dict(title=\"Sharpe Ratio\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Create random portfolio weights and indexes\n",
    "#- How many assests in the portfolio\n",
    "n_assets = 4\n",
    "\n",
    "mean_variance_pairs = []\n",
    "weights_list=[]\n",
    "tickers_list=[]\n",
    "\n",
    "for i in tqdm(range(10000)):\n",
    "    next_i = False\n",
    "    while True:\n",
    "        #- Choose assets randomly without replacement\n",
    "        assets = np.random.choice(list(test_df.columns), n_assets, replace=False)\n",
    "        #- Choose weights randomly ensuring they sum to one\n",
    "        weights = np.random.rand(n_assets)\n",
    "        weights = weights/sum(weights)\n",
    "\n",
    "        #-- Loop over asset pairs and compute portfolio return and variance\n",
    "        portfolio_E_Variance = 0\n",
    "        portfolio_E_Return = 0\n",
    "        for i in range(len(assets)):\n",
    "            portfolio_E_Return += weights[i] * mus.loc[assets[i]]\n",
    "            for j in range(len(assets)):\n",
    "                portfolio_E_Variance += weights[i] * weights[j] * cov.loc[assets[i], assets[j]]\n",
    "\n",
    "        #-- Skip over dominated portfolios\n",
    "        for R,V in mean_variance_pairs:\n",
    "            if (R > portfolio_E_Return) & (V < portfolio_E_Variance):\n",
    "                next_i = True\n",
    "                break\n",
    "        if next_i:\n",
    "            break\n",
    "\n",
    "        #-- Add the mean/variance pairs to a list for plotting\n",
    "        mean_variance_pairs.append([portfolio_E_Return, portfolio_E_Variance])\n",
    "        weights_list.append(weights)\n",
    "        tickers_list.append(assets)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_variance_pairs = np.array(mean_variance_pairs)\n",
    "\n",
    "risk_free_rate=0 #-- Include risk free rate here\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=mean_variance_pairs[:,1]**0.5, y=mean_variance_pairs[:,0], \n",
    "                      marker=dict(color=(mean_variance_pairs[:,0]-risk_free_rate)/(mean_variance_pairs[:,1]**0.5), \n",
    "                                  showscale=True, \n",
    "                                  size=7,\n",
    "                                  line=dict(width=1),\n",
    "                                  colorscale=\"RdBu\",\n",
    "                                  colorbar=dict(title=\"Sharpe<br>Ratio\")\n",
    "                                 ), \n",
    "                      mode='markers',\n",
    "                      text=[str(np.array(tickers_list[i])) + \"<br>\" + str(np.array(weights_list[i]).round(2)) for i in range(len(tickers_list))]))\n",
    "fig.update_layout(template='plotly_white',\n",
    "                  xaxis=dict(title='Annualised Risk (Volatility)'),\n",
    "                  yaxis=dict(title='Annualised Return'),\n",
    "                  title='Sample of Random Portfolios',\n",
    "                  width=850,\n",
    "                  height=500)\n",
    "# fig.update_xaxes(range=[0.18, 0.35])\n",
    "# fig.update_yaxes(range=[0.05,0.29])\n",
    "fig.update_layout(coloraxis_colorbar=dict(title=\"Sharpe Ratio\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define your expected returns and covariance matrix\n",
    "# You should replace these with your own data\n",
    "expected_returns = df.query(\"Period=='2000s'\").drop([\"Date\",\"Period\",\"U.S. 30 Day TBill TR \"],axis=1).mean()\n",
    "cov_matrix = df.query(\"Period=='2000s'\").drop([\"Date\",\"Period\", \"U.S. 30 Day TBill TR \"],axis=1).cov()\n",
    "\n",
    "# Define the target portfolio mean return\n",
    "target_mean_return = 5.5\n",
    "\n",
    "# Define the objective function to minimize standard deviation\n",
    "def portfolio_volatility(weights):\n",
    "    portfolio_return = np.sum(expected_returns * weights)\n",
    "    portfolio_stddev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return portfolio_stddev\n",
    "\n",
    "# Define the constraint for the portfolio mean return\n",
    "def return_constraint(weights):\n",
    "    return np.sum(expected_returns * weights) - target_mean_return\n",
    "\n",
    "# Initial guess for portfolio weights (uniform allocation)\n",
    "initial_weights = np.array([1.0 / len(expected_returns)] * len(expected_returns))\n",
    "\n",
    "# Define the optimization problem\n",
    "constraints = ({'type': 'eq', 'fun': return_constraint})\n",
    "bounds = tuple((0, 1) for _ in range(len(expected_returns)))  # Bounds for weights (0 <= weight <= 1)\n",
    "optimal_weights = minimize(portfolio_volatility, initial_weights, method='SLSQP', constraints=constraints, bounds=bounds)\n",
    "\n",
    "# Extract the optimal portfolio weights\n",
    "optimal_weights = optimal_weights.x\n",
    "\n",
    "# Calculate the minimum unconstrained standard deviation\n",
    "min_std_dev = portfolio_volatility(optimal_weights)\n",
    "\n",
    "# Calculate the portfolio mean return for the minimum unconstrained standard deviation\n",
    "portfolio_mean_return = np.sum(expected_returns * optimal_weights)\n",
    "\n",
    "print(\"Minimum Unconstrained Standard Deviation:\", min_std_dev)\n",
    "print(\"Portfolio Mean Return:\", portfolio_mean_return)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_returns.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_returns = df.query(\"Period=='2000s'\").drop([\"Date\",\"Period\",\"U.S. 30 Day TBill TR \"],axis=1).mean()\n",
    "cov_matrix = df.query(\"Period=='2000s'\").drop([\"Date\",\"Period\", \"U.S. 30 Day TBill TR \"],axis=1).cov()\n",
    "rows = []\n",
    "target_mean_returns = [5.5, 8.2, 11.0, 13.9, 15.2, 17.1, 19.7, 21.3, 23.2, 24.8]\n",
    "# Loop through each target mean return and optimize the portfolio\n",
    "for target_mean_return in target_mean_returns:\n",
    "    # Define the constraint function for the current target mean return\n",
    "    def portfolio_std_deviation(weights,cov_matrix):\n",
    "        portfolio_stddev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        return portfolio_stddev\n",
    "\n",
    "    # Define the constraint function for target mean return\n",
    "    def mean_return_constraint(weights):\n",
    "        return np.sum(expected_returns * weights) - target_mean_return\n",
    "\n",
    "    # Define the constraint to ensure the weights add up to 1 (fully invested)\n",
    "    def budget_constraint(weights):\n",
    "        return np.sum(weights) - 1\n",
    "\n",
    "    # Define the initial guess for portfolio weights\n",
    "    initial_weights = np.ones(len(expected_returns)) / len(expected_returns)\n",
    "\n",
    "    # Define bounds for the weights (0 to 1, meaning fully invested or not invested)\n",
    "    bounds = [(0, 1) for _ in expected_returns]\n",
    "\n",
    "    # Define the optimization problem with both constraints\n",
    "    constraints = [{'type': 'eq', 'fun': mean_return_constraint},\n",
    "                   {'type': 'eq', 'fun': budget_constraint}]\n",
    "\n",
    "    # Use the minimize function to solve the optimization problem\n",
    "    optimal_weights = minimize(\n",
    "        portfolio_std_deviation,         # Objective function to minimize\n",
    "        initial_weights, \n",
    "        cov_matrix,   \n",
    "        method='SLSQP',                 # Sequential Least Squares Quadratic Programming\n",
    "        constraints=constraints,         # Constraints\n",
    "        bounds=bounds                    # Bounds for asset weights\n",
    "    )\n",
    "\n",
    "    # Extract the optimized portfolio weights\n",
    "    optimized_weights = optimal_weights.x\n",
    "\n",
    "    # Calculate the minimum standard deviation for the current target\n",
    "    min_std_dev = portfolio_std_deviation(optimized_weights, cov_matrix)\n",
    "\n",
    "    # Print the results for the current target\n",
    "    print(f\"Target Mean Return: {target_mean_return}\")\n",
    "    print(\"Optimal Portfolio Weights:\", optimized_weights)\n",
    "    print(\"Minimum Portfolio Standard Deviation:\", min_std_dev)\n",
    "    print(\"-\" * 40)  # Separator for clarity\n",
    "    row = [min_std_dev] + optimized_weights.tolist() + [np.dot(expected_returns, optimized_weights)]\n",
    "    rows.append(row)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows,columns=[\"min_std_dev\"]+expected_returns.index.tolist()+[\"portfolio_mean_return\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [pd.DataFrame(target_mean_returns,columns=[\"target_mean_returns\"]),\n",
    "    df],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(expected_returns, optimized_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_weights.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define your expected returns and covariance matrix\n",
    "# You should replace these with your own data\n",
    "expected_returns = df.query(\"Period=='2000s'\").drop([\"Date\",\"Period\"],axis=1).mean()\n",
    "cov_matrix = df.query(\"Period=='2000s'\").drop([\"Date\",\"Period\"],axis=1).cov()\n",
    "\n",
    "# Define the target portfolio mean return\n",
    "target_mean_return = 5.5\n",
    "\n",
    "# Genetic Algorithm Parameters\n",
    "population_size = 10000\n",
    "num_generations = 100\n",
    "crossover_prob = 0.7\n",
    "mutation_prob = 0.2\n",
    "\n",
    "# Define the chromosome length (number of assets)\n",
    "chromosome_length = len(expected_returns)\n",
    "\n",
    "# Define the fitness function\n",
    "def portfolio_fitness(weights):\n",
    "    portfolio_return = np.sum(expected_returns * weights)\n",
    "    portfolio_stddev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return portfolio_stddev,  # Note the comma to return a tuple\n",
    "\n",
    "# Initialize the population with random portfolios\n",
    "population = [np.random.rand(chromosome_length) for _ in range(population_size)]\n",
    "\n",
    "for generation in range(num_generations):\n",
    "    print(\"Generation %d...\" % generation)\n",
    "    # Evaluate the fitness of each portfolio in the population\n",
    "    fitness_scores = [portfolio_fitness(weights) for weights in population]\n",
    "\n",
    "    # Select portfolios for crossover\n",
    "    selected_indices = np.random.choice(population_size, size=population_size, replace=True)\n",
    "    selected_portfolios = [population[i] for i in selected_indices]\n",
    "\n",
    "    # Perform crossover\n",
    "    offspring = []\n",
    "    for i in range(0, population_size, 2):\n",
    "        parent1, parent2 = selected_portfolios[i], selected_portfolios[i + 1]\n",
    "        if random.random() < crossover_prob:\n",
    "            crossover_point = random.randint(1, chromosome_length - 1)\n",
    "            child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "            child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n",
    "        else:\n",
    "            child1, child2 = parent1.copy(), parent2.copy()\n",
    "        offspring.extend([child1, child2])\n",
    "\n",
    "    # Perform mutation\n",
    "    for i in range(population_size):\n",
    "        if random.random() < mutation_prob:\n",
    "            mutation_point = random.randint(0, chromosome_length - 1)\n",
    "            population[i][mutation_point] = random.random()\n",
    "\n",
    "    # Replace the old population with the new population\n",
    "    population = offspring\n",
    "\n",
    "# Find the best portfolio in the final population\n",
    "best_portfolio = min(population, key=lambda weights: portfolio_fitness(weights))\n",
    "\n",
    "# Calculate the portfolio mean return and standard deviation\n",
    "best_portfolio_return = np.sum(expected_returns * best_portfolio)\n",
    "best_portfolio_stddev = np.sqrt(np.dot(best_portfolio.T, np.dot(cov_matrix, best_portfolio)))\n",
    "\n",
    "print(\"Best Portfolio Weights:\", best_portfolio)\n",
    "print(\"Best Portfolio Mean Return:\", best_portfolio_return)\n",
    "print(\"Best Portfolio Standard Deviation:\", best_portfolio_stddev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06416920407599999, 0.021953809847000016, 0.0902087, 0.06450622529000001]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_returns = test_df.mean()*12\n",
    "expected_returns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyuwu/Library/Caches/pypoetry/virtualenvs/asset-allocation-project-ax0yMTeZ-py3.11/lib/python3.11/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/Users/hanyuwu/Library/Caches/pypoetry/virtualenvs/asset-allocation-project-ax0yMTeZ-py3.11/lib/python3.11/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t100000\n",
      "1  \t60205 \n",
      "2  \t59926 \n",
      "3  \t60024 \n",
      "4  \t60124 \n",
      "5  \t59921 \n",
      "6  \t60170 \n",
      "7  \t60177 \n",
      "8  \t60221 \n",
      "9  \t59840 \n",
      "10 \t60027 \n",
      "11 \t59966 \n",
      "12 \t59897 \n",
      "13 \t59998 \n",
      "14 \t59978 \n",
      "15 \t60009 \n",
      "16 \t60262 \n",
      "17 \t60251 \n",
      "18 \t60033 \n",
      "19 \t59770 \n",
      "20 \t59968 \n",
      "21 \t60193 \n",
      "22 \t60128 \n",
      "23 \t60274 \n",
      "24 \t59786 \n",
      "25 \t60022 \n",
      "26 \t60169 \n",
      "27 \t60248 \n",
      "28 \t60178 \n",
      "29 \t59922 \n",
      "30 \t60056 \n",
      "31 \t60008 \n",
      "32 \t59875 \n",
      "33 \t60102 \n",
      "34 \t60024 \n",
      "35 \t59957 \n",
      "36 \t59903 \n",
      "37 \t59905 \n",
      "38 \t59918 \n",
      "39 \t59810 \n",
      "40 \t59933 \n",
      "41 \t60182 \n",
      "42 \t59918 \n",
      "43 \t60059 \n",
      "44 \t60149 \n",
      "45 \t60031 \n",
      "46 \t60022 \n",
      "47 \t59905 \n",
      "48 \t60120 \n",
      "49 \t59753 \n",
      "50 \t60215 \n",
      "51 \t60102 \n",
      "52 \t59728 \n",
      "53 \t60235 \n",
      "54 \t59810 \n",
      "55 \t59977 \n",
      "56 \t60169 \n",
      "57 \t59763 \n",
      "58 \t60291 \n",
      "59 \t60007 \n",
      "60 \t60147 \n",
      "61 \t60053 \n",
      "62 \t60115 \n",
      "63 \t59834 \n",
      "64 \t60149 \n",
      "65 \t59912 \n",
      "66 \t59677 \n",
      "67 \t60021 \n",
      "68 \t60102 \n",
      "69 \t59855 \n",
      "70 \t59756 \n",
      "71 \t59969 \n",
      "72 \t59865 \n",
      "73 \t59865 \n",
      "74 \t60057 \n",
      "75 \t60176 \n",
      "76 \t59761 \n",
      "77 \t59884 \n",
      "78 \t60373 \n",
      "79 \t59883 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m population \u001b[39m=\u001b[39m toolbox\u001b[39m.\u001b[39mpopulation(n\u001b[39m=\u001b[39mpopulation_size)\n\u001b[1;32m     53\u001b[0m \u001b[39m# Run the genetic algorithm\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m final_population, _ \u001b[39m=\u001b[39m algorithms\u001b[39m.\u001b[39;49meaMuPlusLambda(population, toolbox, mu\u001b[39m=\u001b[39;49mpopulation_size, lambda_\u001b[39m=\u001b[39;49mpopulation_size, \n\u001b[1;32m     55\u001b[0m                                                 cxpb\u001b[39m=\u001b[39;49mcrossover_prob, mutpb\u001b[39m=\u001b[39;49mmutation_prob, ngen\u001b[39m=\u001b[39;49mnum_generations,\n\u001b[1;32m     56\u001b[0m                                                 stats\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, halloffame\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     58\u001b[0m \u001b[39m# Select the best portfolio from the final population\u001b[39;00m\n\u001b[1;32m     59\u001b[0m best_portfolio \u001b[39m=\u001b[39m tools\u001b[39m.\u001b[39mselBest(final_population, k\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/asset-allocation-project-ax0yMTeZ-py3.11/lib/python3.11/site-packages/deap/algorithms.py:321\u001b[0m, in \u001b[0;36meaMuPlusLambda\u001b[0;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    319\u001b[0m invalid_ind \u001b[39m=\u001b[39m [ind \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m offspring \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ind\u001b[39m.\u001b[39mfitness\u001b[39m.\u001b[39mvalid]\n\u001b[1;32m    320\u001b[0m fitnesses \u001b[39m=\u001b[39m toolbox\u001b[39m.\u001b[39mmap(toolbox\u001b[39m.\u001b[39mevaluate, invalid_ind)\n\u001b[0;32m--> 321\u001b[0m \u001b[39mfor\u001b[39;00m ind, fit \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(invalid_ind, fitnesses):\n\u001b[1;32m    322\u001b[0m     ind\u001b[39m.\u001b[39mfitness\u001b[39m.\u001b[39mvalues \u001b[39m=\u001b[39m fit\n\u001b[1;32m    324\u001b[0m \u001b[39m# Update the hall of fame with the generated individuals\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m, in \u001b[0;36mevaluate_portfolio\u001b[0;34m(individual)\u001b[0m\n\u001b[1;32m     23\u001b[0m portfolio_return \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(expected_returns[i] \u001b[39m*\u001b[39m w \u001b[39mfor\u001b[39;00m i, w \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(individual))\n\u001b[1;32m     24\u001b[0m portfolio_cov_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[cov_matrix[i][j] \u001b[39m*\u001b[39m w1 \u001b[39m*\u001b[39m w2 \u001b[39mfor\u001b[39;00m i, w1 \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(individual)] \u001b[39mfor\u001b[39;00m j, w2 \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(individual)])\n\u001b[0;32m---> 25\u001b[0m portfolio_stddev \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39mdot(individual, np\u001b[39m.\u001b[39;49mdot(portfolio_cov_matrix, individual)))\n\u001b[1;32m     27\u001b[0m \u001b[39m# Penalize portfolios that do not meet constraints\u001b[39;00m\n\u001b[1;32m     28\u001b[0m deviation_from_target \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(portfolio_return \u001b[39m-\u001b[39m target_mean_return)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# Define the problem as a minimization problem\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "# Define the problem-specific functions and constraints\n",
    "\n",
    "# Dummy data for expected returns and covariance matrix\n",
    "expected_returns = [0.06416920407599999, 0.021953809847000016, 0.0902087, 0.06450622529000001]\n",
    "cov_matrix = [[4.43902182e-02, 3.03961209e-02, 1.63717276e-03, 3.41134446e-02],\n",
    "       [3.03961209e-02, 2.53635406e-02, 1.00647360e-03, 2.76667501e-02],\n",
    "       [1.63717276e-03, 1.00647360e-03, 2.24798104e-02, 5.95227542e-05],\n",
    "       [3.41134446e-02, 2.76667501e-02, 5.95227542e-05, 3.76493663e-02]\n",
    "]\n",
    "\n",
    "target_mean_return = 5.5\n",
    "\n",
    "def evaluate_portfolio(individual):\n",
    "    # Calculate portfolio return and standard deviation\n",
    "    portfolio_return = sum(expected_returns[i] * w for i, w in enumerate(individual))\n",
    "    portfolio_cov_matrix = np.array([[cov_matrix[i][j] * w1 * w2 for i, w1 in enumerate(individual)] for j, w2 in enumerate(individual)])\n",
    "    portfolio_stddev = np.sqrt(np.dot(individual, np.dot(portfolio_cov_matrix, individual)))\n",
    "\n",
    "    # Penalize portfolios that do not meet constraints\n",
    "    deviation_from_target = abs(portfolio_return - target_mean_return)\n",
    "    penalty = deviation_from_target  # Adjust penalty as needed\n",
    "\n",
    "    return portfolio_stddev + penalty,\n",
    "\n",
    "# Genetic Algorithm Parameters\n",
    "population_size = 100000\n",
    "num_generations = 1000\n",
    "crossover_prob = 0.5\n",
    "mutation_prob = 0.1\n",
    "chromosome_length = 4  # Number of assets\n",
    "\n",
    "# Create a toolbox for the GA\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.uniform, 0, 1)  # Gene values (weights)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, chromosome_length)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evaluate_portfolio)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)  # Blend crossover\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.2, indpb=mutation_prob)  # Gaussian mutation\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# Create an initial population\n",
    "population = toolbox.population(n=population_size)\n",
    "\n",
    "# Run the genetic algorithm\n",
    "final_population, _ = algorithms.eaMuPlusLambda(population, toolbox, mu=population_size, lambda_=population_size, \n",
    "                                                cxpb=crossover_prob, mutpb=mutation_prob, ngen=num_generations,\n",
    "                                                stats=None, halloffame=None, verbose=True)\n",
    "\n",
    "# Select the best portfolio from the final population\n",
    "best_portfolio = tools.selBest(final_population, k=1)[0]\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Portfolio Weights:\", best_portfolio)\n",
    "print(\"Best Portfolio Mean Return:\", sum(expected_returns[i] * best_portfolio[i] for i in range(len(best_portfolio))))\n",
    "print(\"Best Portfolio Standard Deviation:\", evaluate_portfolio(best_portfolio)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Portfolio Weights: [0.22356607475700002, 0.10254134508346303, 0.4088421200492207, 0.2540224261302224]\n",
      "Best Portfolio Mean Return: 0.0698643742705228\n",
      "Best Portfolio Standard Deviation: 5.465067813900535\n"
     ]
    }
   ],
   "source": [
    "best_portfolio = tools.selBest(final_population, k=1)[0]\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Portfolio Weights:\", best_portfolio)\n",
    "print(\"Best Portfolio Mean Return:\", sum(expected_returns[i] * best_portfolio[i] for i in range(len(best_portfolio))))\n",
    "print(\"Best Portfolio Standard Deviation:\", evaluate_portfolio(best_portfolio)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m../data/processed/processed_data.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"../data/processed/processed_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asset-allocation-project-ax0yMTeZ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
